# Projeto-IBRA
Principais resultados obtidos no segundo semestre de 2021 em um iniciação científica como foco uso de técnincas de NPL para desenvolvimento de IA explicativas.


Explainable AI é uma área de pesquisa que tem buscado promover transparência em modelos existentes e criar novos modelos que já incorporem esta característica “by design”, isto é, que conseguem explicar suas próprias decisões. Este projeto tem por objetivo colaborar no desenvolvimento de modelos explicáveis para a moderação de conteúdos em redes sociais. Ele se divide em duas frentes: na coleta de dados e processamento desses com intuito de simular um ambiente de rede social; a segunda foca em aumentar explicabilidade de modelos pré-existentes para moderação de discurso de ódio e notícias falsas (fake news), sendo realizado em parceria com veículos de imprensa. Buscaremos desenvolver modelos que possam ser colocados em produção e ajudar a sociedade.
 
O projeto se dividirá em duas frentes:
 
1. A primeira frente focará no prospecção e análise de dados, e no desenvolvimento de métodos e modelos para criar e analisar com mais clareza os recursos de texto, usando técnicas como data augmentation, data mining, entre outras.
 
2. A segunda frente foca no problema de discurso de ódio e notícias falsas. Nesta frente, desenvolvemos modelos externos que explicarão os modelos já existentes.
 
Faço parte do primeiro grupo que vem analisando um modelo desenvolvido pelo grupo de pesquisa e está sendo aplicado a dados de discurso de ódio, a fim de criar um classificador usando poucos dados para treinamento.
